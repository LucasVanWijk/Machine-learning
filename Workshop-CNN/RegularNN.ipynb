{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from load_data import load_train, load_test, load_example\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.utils import to_categorical\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image recognition met een \"normaal\" neuraal netwerk. \n",
    "\n",
    "Neurale netwerken zijn ontzettend sterke wiskundige modellen. Een “normaal” neuraal netwerk heeft echter wel wat limieten. Om een aantal van deze limieten te doorbreken, kan je een convolutional neuraal netwerk gebruiken. \n",
    "\n",
    "We beginnen met het exploreren van de limieten van normale neurale netwerken, dit doen we doormiddel van de MNIST-dataset.\n",
    "\n",
    "MNIST is een dataset van 70.000 handgeschreven cijfers (0..9), opgesplitst in 60.000 training images en 10.000 testing images. We hebben al functies geschreven waarmee je de data kan inladen, zie de cell hieronder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 31)\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = load_train()\n",
    "X_train = (X_train / 255) - 0.5\n",
    "\n",
    "plt.imshow(X_train[2])\n",
    "plt.title(f\"{y_train[2]}\")\n",
    "plt.show()\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dit is, uiteraard, een vier.\n",
    "\n",
    "### Data formatting\n",
    "Voordat we een neuraal netwerk kunnen trainen op de MNIST-data, moet deze verwerkt worden. De input van dit neuraal netwerk moet 1-dimensionaal zijn, momenteel is dat nog 2-dimensionaal. De labels hebben wij zelf al voor je verwerkt, probeer nu zelf X_train om te zetten naar een correct format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train, 10)\n",
    "X_train_flat = X_train.reshape((60000, 868)) # FIXME Zet mij in de goede vorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n"
     ]
    }
   ],
   "source": [
    "X_train_flat.shape\n",
    "print(X_train.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image recognition geeft in het algemeen ontzettend grote input vectors. MNIST is in grayscale, maar veel plaatjes zijn dat niet. Als je ook nog kleur wil meegeven, zou de input vector nog drie keer zo groot zijn.\n",
    "\n",
    "### Bouwen van een NN\n",
    "\n",
    "De volgende stap is om een neuraal netwerk te bouwen. Maak zelf de eerste Dense layer af, kijk vervolgens ook naar hoeveel hidden layers je toevoegt. Bij image recognition is de activation function ook erg belangrijk. Denk goed na over welke je gebruikt. De laatste layer geven wij alvast aan je. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 32)                27808     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 21)                693       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                220       \n",
      "=================================================================\n",
      "Total params: 28,721\n",
      "Trainable params: 28,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "# input_dimensions equals the size of a single image\n",
    "model.add(Dense(32, activation=\"relu\", input_dim=868))\n",
    "model.add(Dense(21, input_dim=32)) \n",
    "model.add(Dense(10, activation=\"softmax\"))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hieruit kan je al direct het eerste probleem van normale neurale netwerken inzien; er is een gigantische hoeveelheid trainbare parameters. \n",
    "\n",
    "Iedere node moet verbonden zijn aan iedere node. Bij image recognition is de input vector gigantisch, dit houdt dus ook in dat er een gigantische hoeveelheid weights zijn waarmee jouw neuraal netwerk rekening moet houden. \n",
    "\n",
    "Dit maakt het trainen best zwaar en langzaam. Ga nu door met het trainen van dit neuraal netwerk. Ook de `.compile()` hebben wij al aan je geven, ook hier mag je mee spelen.\n",
    "\n",
    "Probeer jouw neuraal netwerk zo accuraat mogelijk te maken. (doe dit door te kijken naar de resultaten van de `.fit()`, `.evaluate()` komt later)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected dense_3 to have 2 dimensions, but got array with shape (60000, 10, 10)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-eb3756a585fd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_flat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# FIXME set epochs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1152\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1153\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1154\u001b[1;33m             batch_size=batch_size)\n\u001b[0m\u001b[0;32m   1155\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1156\u001b[0m         \u001b[1;31m# Prepare validation data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m    619\u001b[0m                 \u001b[0mfeed_output_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    620\u001b[0m                 \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 621\u001b[1;33m                 exception_prefix='target')\n\u001b[0m\u001b[0;32m    622\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    623\u001b[0m             \u001b[1;31m# Generate sample-wise weight values given the `sample_weight` and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    133\u001b[0m                         \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' dimensions, but got array '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 135\u001b[1;33m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[0;32m    136\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking target: expected dense_3 to have 2 dimensions, but got array with shape (60000, 10, 10)"
     ]
    }
   ],
   "source": [
    "model.fit(X_train_flat, y_train, epochs= 20) # FIXME set epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Het evalueren van het neurale netwerk\n",
    "Ook hier moet de data eerst nog omgevormd worden, gebruik hiervoor dezelfde code als bij de training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = load_test()\n",
    "X_test = \n",
    "y_test = to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Huh?\n",
    "Hoogstwaarschijnlijk scoort jouw neuraal netwerk nu ontzettend slecht. Om een limiet van neurale netwerken zichtbaar te maken, hebben we een klein beetje valsgespeeld. We hebben wat padding toegevoegd; een aantal pixels aan de linkerkant bij de testing data en een aantal pixels aan de rechterkant bij de training data. Zie de plots hieronder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(example_r, example_l), label = load_example()\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "axs[0].imshow(example_r)\n",
    "axs[0].set_title(\"Padding on right side (Like training)\")\n",
    "\n",
    "axs[1].imshow(example_l)\n",
    "axs[1].set_title(\"Padding on left side (Like testing)\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De standaardwaarde voor de padding is 3(!!) pixels, dit heeft een gigantisch effect op de accuratesse. Formatteer nog één keer de data (`examples`), en kijk wat er uit de `.predict()` komt. \n",
    "\n",
    "Er bestaat een kans dat jouw model hier de goede voorspelt, probeer dan bij `load_example()` het argument `index` te veranderen naar een ander getal. Waarschijnlijk zal het dan wel fout voorspellen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = np.array([example_r, example_l]) # FIXME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict_classes(examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Waarom?\n",
    "\n",
    "De voorspellingen van een gewoon neuraal netwerk zijn ruimtelijk bepaald, het herkent patronen op specifieke plekken. Het verplaatsen van deze patronen met maar een paar pixels kan al genoeg zijn om het onmogelijk te maken voor een gewoon neuraal netwerk om deze te herkennen. \n",
    "\n",
    "Een neuraal netwerk getraind op het herkennen van honden en fietsen, zou heel makkelijk het volgende gedrag kunnen laten zien:\n",
    "\n",
    "\n",
    "\n",
    "![Right!](src/top-left-dog.png)\n",
    "\n",
    "![Wrong!](src/top-left-bike.png)\n",
    "\n",
    "\n",
    "Speel is een beetje rond met de padding, kijk is hoeveel impact 4 pixels heeft, zelfs 1 pixel kan al een grote impact hebben!\n",
    "\n",
    "Wij raden aan om alleen de horizontale padding te veranderen, het format van het padding argument in `load_train`, `load_test`, en `load_example` is dan: `((0, 0), (0, 0), (left sided padding, right sided padding))`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Aldewereld, H. & van der Bijl, B. & Bunk, J. (2017, oktober). Applied Artificial Intelligence. Geraadpleegd op 13 maart 2020, van https://canvas.hu.nl/courses/7569/files/694738/download?wrap=1\n",
    "\n",
    "- Chollet, F. (2019, November 6). Getting started with the Keras Sequential model. Geraadpleegd op 13 maart 2020, van keras.io: https://keras.io/getting-started/sequential-model-guide/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
